# %% [markdown]
# Ingest√£o e Explora√ß√£o dos Dados
# 
# Configura√ß√£o Inicial

# %%
# C√©lula 1: Imports e Configura√ß√µes
import pandas as pd
import sqlite3
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime

# Configura√ß√µes visuais
sns.set_theme(style="whitegrid", palette="husl")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['font.size'] = 11

print("‚úÖ Bibliotecas importadas com sucesso!")

# %% [markdown]
# Carregamento dos Dados

# %%
# C√©lula 2: Carregamento dos JSONs
df_accounts = pd.read_json('../data/raw/accounts_anonymized.json')
df_cases = pd.read_json('../data/raw/support_cases_anonymized.json')

# Converter colunas de data imediatamente (JSON carrega datas como strings)
# Isso facilita o trabalho com SQL mais tarde
df_accounts['account_created_date'] = pd.to_datetime(df_accounts['account_created_date'])
df_cases['case_created_date'] = pd.to_datetime(df_cases['case_created_date'])
df_cases['case_closed_date'] = pd.to_datetime(df_cases['case_closed_date'])

print(f"üìä Accounts carregados: {len(df_accounts)} registros")
print(f"üìä Cases carregados: {len(df_cases)} registros")

# %% [markdown]
# An√°lise Explorat√≥ria Detalhada

# %%
# C√©lula 3: Estrutura e Qualidade - Accounts
print("=" * 80)
print("AN√ÅLISE: ACCOUNTS")
print("=" * 80)

print("\nüìã Informa√ß√µes Gerais:")
print(df_accounts.info())

print("\nüìä Resumo Categ√≥rico (Top valores):")
cols_cat = ['account_country', 'account_industry']
display(df_accounts[cols_cat].describe())

print("\nüìÖ Resumo Temporal:")
print(f"Primeira conta criada em: {df_accounts['account_created_date'].min()}")
print(f"√öltima conta criada em:   {df_accounts['account_created_date'].max()}")
print(f"Per√≠odo total de dados:   {df_accounts['account_created_date'].max() - df_accounts['account_created_date'].min()}")

print("\nüîç Primeiras 5 linhas:")
display(df_accounts.head())

print("\n‚ö†Ô∏è Valores Nulos:")
print(df_accounts.isnull().sum())

print("\nüîë Colunas dispon√≠veis:")
print(df_accounts.columns.tolist())

# %%
# C√©lula 4: Estrutura e Qualidade - Cases
print("=" * 80)
print("AN√ÅLISE: SUPPORT CASES")
print("=" * 80)

print("\nüìã Informa√ß√µes Gerais:")
print(df_cases.info())

cols_negocio = ['case_status', 'case_priority', 'case_severity', 'case_product']

print("\nüìä Distribui√ß√£o de M√©tricas Chave (Top 5):")
for col in cols_negocio:
    print(f"\n--- {col.upper()} ---")
    # Mostra contagem e % relativa lado a lado
    dist = pd.concat([df_cases[col].value_counts(), 
                      df_cases[col].value_counts(normalize=True).mul(100).round(1)], 
                     axis=1, keys=['Qtd', '%'])
    display(dist)

print("\nüìÖ Resumo Temporal dos Casos:")
print(f"Primeiro caso: {df_cases['case_created_date'].min()}")
print(f"√öltimo caso:   {df_cases['case_created_date'].max()}")

print("\n‚ö†Ô∏è Valores Nulos (Importante para identificar casos abertos):")
print(df_cases.isnull().sum())

# %% [markdown]
# Identifica√ß√£o de Relacionamentos

# %%
# C√©lula 5: Verifica√ß√£o de Integridade (Abordagem Vetorizada)

# 1. Identificar IDs v√°lidos (Conjunto de refer√™ncia)
valid_account_ids = set(df_accounts['account_sfid'])

# 2. Criar a coluna de status com um valor padr√£o
df_cases['integrity_status'] = 'Valid Link'

# 3. Marcar os Nulos (R√°pido e direto)
df_cases.loc[df_cases['account_sfid'].isnull(), 'integrity_status'] = 'Orphan (Null ID)'

# 4. Marcar os Links Quebrados (IDs que n√£o s√£o nulos, mas n√£o est√£o na lista de contas)
# O operador ~ significa "N√ÉO". Ou seja: Onde o ID N√ÉO est√° em valid_account_ids
broken_link_mask = (~df_cases['account_sfid'].isin(valid_account_ids)) & (df_cases['account_sfid'].notnull())
df_cases.loc[broken_link_mask, 'integrity_status'] = 'Orphan (Broken Link)'

# === Relat√≥rio ===
print("=== Relat√≥rio de Integridade ===")
print(df_cases['integrity_status'].value_counts())

# Exibir amostra dos problemas, se houver
orphans = df_cases[df_cases['integrity_status'] != 'Valid Link']
if not orphans.empty:
    print(f"\nAlerta: Encontrados {len(orphans)} registros √≥rf√£os.")
    display(orphans[['case_number', 'account_sfid', 'integrity_status']].head())

# %%
# C√©lula 6: Tratamento dos √ìrf√£os (Data Cleaning)

# Em vez de apagar, vamos preencher os Nulos para evitar erros no SQL depois
df_cases['account_sfid'] = df_cases['account_sfid'].fillna('UNKNOWN_ACCOUNT')

# Opcional: Se quiser ser muito proativo, crie uma conta "fict√≠cia" no df_accounts
# para que o JOIN no SQL n√£o descarte esses dados.
unknown_account = {
    'account_sfid': 'UNKNOWN_ACCOUNT',
    'account_name': 'Unassigned / Data Error',
    'account_industry': 'Unknown',
    'account_country': 'Unknown'
}

# Adiciona essa conta "coringa" ao DataFrame de contas se ela n√£o existir
if 'UNKNOWN_ACCOUNT' not in df_accounts['account_sfid'].values:
    df_accounts = pd.concat([df_accounts, pd.DataFrame([unknown_account])], ignore_index=True)

print("Limpeza realizada: √ìrf√£os mapeados para 'UNKNOWN_ACCOUNT'.")

# %% [markdown]
# Processamento com SQL 
# 
# Setup do Banco de Dados In-Memory

# %%
# C√©lula 7: Cria√ß√£o do Banco SQLite em Mem√≥ria
conn = sqlite3.connect(':memory:')

# Carregando dados no SQLite
df_accounts.to_sql('accounts', conn, index=False, if_exists='replace')
df_cases.to_sql('cases', conn, index=False, if_exists='replace')

# Verificando tabelas criadas
tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table'", conn)
print("‚úÖ Tabelas criadas no SQLite:")
print(tables)

# %% [markdown]
# Queries Anal√≠ticas (KPIs de Neg√≥cio)
# 
# KPI 1: Performance por Ind√∫stria

# %%
# C√©lula 8: An√°lise de Volume e Tempo por Ind√∫stria
query_industry = """
SELECT 
    a.account_industry as industry,
    COUNT(c.case_sfid) as total_cases,
    COUNT(DISTINCT c.account_sfid) as unique_accounts,
    -- SQLite usa JULIANDAY para diferen√ßa de datas
    ROUND(AVG(JULIANDAY(c.case_closed_date) - JULIANDAY(c.case_created_date)), 2) as avg_resolution_days,
    COUNT(CASE WHEN c.case_priority IN ('High', 'Urgent') THEN 1 END) as critical_priority_cases,
    ROUND(COUNT(CASE WHEN c.case_priority IN ('High', 'Urgent') THEN 1 END) * 100.0 / COUNT(c.case_sfid), 2) as pct_critical_cases
FROM 
    accounts a
JOIN 
    cases c ON a.account_sfid = c.account_sfid
WHERE 
    c.case_sfid IS NOT NULL
GROUP BY 
    a.account_industry
ORDER BY 
    total_cases DESC;
"""

# Usando nossa fun√ß√£o auxiliar criada anteriormente (ou pd.read_sql)
df_industry_metrics = pd.read_sql(query_industry, conn)

print("üìä KPI 1: M√©tricas por Ind√∫stria")
display(df_industry_metrics)

# %% [markdown]
# KPI 2: An√°lise de Status de Cases

# %%
# C√©lula 9: Distribui√ß√£o de Status
query_status = """
SELECT 
    c.case_status as status,
    COUNT(c.case_sfid) as total_cases,
    -- Tempo de resolu√ß√£o para casos FECHADOS
    ROUND(AVG(JULIANDAY(c.case_closed_date) - JULIANDAY(c.case_created_date)), 2) as avg_days_to_close,
    -- Contagem de Cr√≠ticos (High + Urgent)
    COUNT(CASE WHEN c.case_priority IN ('High', 'Urgent') THEN 1 END) as critical_cases,
    -- Idade m√©dia (Backlog) para casos ABERTOS (considerando 'hoje' como 2025-01-09)
    ROUND(AVG(
        CASE 
            WHEN c.case_closed_date IS NULL 
            THEN JULIANDAY('2025-01-09') - JULIANDAY(c.case_created_date)
            ELSE NULL 
        END
    ), 2) as avg_days_open
FROM 
    cases c
GROUP BY 
    c.case_status
ORDER BY 
    total_cases DESC;
"""

df_status_metrics = pd.read_sql(query_status, conn)
print("üìä KPI 2: An√°lise por Status")
display(df_status_metrics)

# %% [markdown]
# KPI 3: Contas Problem√°ticas (High Touch Accounts)
# 

# %%
# C√©lula 10: Identifica√ß√£o de Contas com Muitos Cases (High Touch)
query_high_touch = """
SELECT 
    a.account_name,
    a.account_industry,
    COUNT(c.case_sfid) as total_cases,
    
    -- M√©trica 1: Criticidade (Prioridade Alta + Urgente)
    COUNT(CASE WHEN c.case_priority IN ('High', 'Urgent') THEN 1 END) as critical_cases,
    
    -- M√©trica 2: Backlog Atual (Casos que n√£o est√£o Fechados nem s√£o Duplicados)
    COUNT(CASE WHEN c.case_status NOT IN ('Closed', 'Duplicate') THEN 1 END) as active_cases,
    
    -- M√©trica 3: % de Criticidade (Ajustado para incluir High e Urgent)
    ROUND(COUNT(CASE WHEN c.case_priority IN ('High', 'Urgent') THEN 1 END) * 100.0 / COUNT(c.case_sfid), 1) as pct_critical

FROM 
    accounts a
JOIN 
    cases c ON a.account_sfid = c.account_sfid
GROUP BY 
    a.account_sfid, a.account_name, a.account_industry
HAVING 
    total_cases > 10
ORDER BY 
    total_cases DESC
LIMIT 15
"""

df_high_touch = pd.read_sql(query_high_touch, conn)
print("üìä KPI 3: Top Clientes por Volume e Carga de Trabalho Atual")
display(df_high_touch)

# %% [markdown]
# KPI 4: An√°lise Temporal

# %%
# C√©lula 11: Tend√™ncias Temporais
query_temporal = """
SELECT 
    strftime('%Y-%m', c.case_created_date) as month,
    COUNT(c.case_sfid) as cases_created,
    COUNT(CASE WHEN c.case_status = 'Closed' THEN 1 END) as cases_closed,
    -- C√°lculo de m√©dia de dias para resolu√ß√£o
    ROUND(AVG(JULIANDAY(c.case_closed_date) - JULIANDAY(c.case_created_date)), 2) as avg_resolution_days
FROM 
    cases c
WHERE
    c.case_created_date IS NOT NULL
GROUP BY 
    strftime('%Y-%m', c.case_created_date)
ORDER BY 
    month
"""

df_temporal = pd.read_sql(query_temporal, conn)
print("üìä KPI 4: Tend√™ncias Mensais")
display(df_temporal.tail(12)) # Mostrando apenas os √∫ltimos 12 meses para n√£o poluir

# %% [markdown]
# Visualiza√ß√µes (Data Storytelling)
# 
# Visualiza√ß√£o 1: Volume por Ind√∫stria

# %%
# C√©lula 12: Gr√°fico de Barras - Top Ind√∫strias
import os

# 1. Garante que o diret√≥rio de sa√≠da existe (evita erro de FileNotFoundError)
os.makedirs('../output/figures', exist_ok=True)

plt.figure(figsize=(14, 8))

# Garante que pegamos apenas o top 10 ordenado
top_industries = df_industry_metrics.sort_values('total_cases', ascending=False).head(10)

# 2. Plotagem corrigida (adicionado hue e legend=False para evitar warnings recentes do Seaborn)
ax = sns.barplot(
    data=top_industries, 
    y='industry', 
    x='total_cases', 
    hue='industry',  # Boas pr√°ticas do Seaborn novo
    palette='viridis',
    legend=False
)

plt.title('Top 10 Ind√∫strias por Volume de Casos de Suporte', 
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('N√∫mero Total de Cases', fontsize=13)
plt.ylabel('Ind√∫stria', fontsize=13)

# 3. Adicionar valores nas barras (Ajuste de posi√ß√£o din√¢mica)
for i, v in enumerate(top_industries['total_cases']):
    # O offset (+ v * 0.01) coloca o texto um pouco √† frente da barra proporcionalmente
    ax.text(v + (v * 0.01), i, f'{v:,.0f}', va='center', fontsize=10, fontweight='bold')

plt.tight_layout()

# Salva a figura
plt.savefig('../output/figures/01_volume_por_industria.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo em: ../output/figures/01_volume_por_industria.png")

plt.show()

# %% [markdown]
# Visualiza√ß√£o 2: Tempo de Resolu√ß√£o

# %%
# C√©lula 13: Gr√°fico de Barras Horizontal - Tempo de Resolu√ß√£o (Corrigido Definitivo)
plt.figure(figsize=(14, 8))

# 1. FILTRO DE RELEV√ÇNCIA
df_relevante = df_industry_metrics[df_industry_metrics['total_cases'] > 20].copy()

# 2. CORRE√á√ÉO DO ERRO VISUAL (TRATAMENTO DE NULOS)
# Substitui valores None/NaN por uma string para que o Seaborn consiga plotar a barra
df_relevante['industry'] = df_relevante['industry'].fillna('No Industry Defined')

# 3. Seleciona as 10 ind√∫strias mais lentas
top_resolution = df_relevante.nlargest(10, 'avg_resolution_days')

# Plotagem
ax = sns.barplot(
    data=top_resolution, 
    y='industry', 
    x='avg_resolution_days', 
    hue='industry', 
    palette='rocket', 
    legend=False
)

plt.title('Top 10 Ind√∫strias (Relevantes) com Maior Tempo M√©dio de Resolu√ß√£o', 
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Tempo M√©dio de Resolu√ß√£o (dias)', fontsize=13)
plt.ylabel('Ind√∫stria', fontsize=13)

# Adicionar valores nas barras
for i, v in enumerate(top_resolution['avg_resolution_days']):
    # Ajuste fino: Se o valor for muito pequeno, afasta um pouco mais
    offset = v * 0.01 if v > 1 else 0.1
    ax.text(v + offset, i, f'{v:.1f}d', va='center', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.savefig('../output/figures/02_tempo_resolucao.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo em: ../output/figures/02_tempo_resolucao_fixed.png")

plt.show()

# %% [markdown]
# Visualiza√ß√£o 3: Distribui√ß√£o de Status

# %%
# C√©lula 14: Gr√°fico de Pizza - Status dos Cases

plt.figure(figsize=(10, 6))

# Defini√ß√£o de cores
colors = sns.color_palette('pastel', len(df_status_metrics))
explode = [0.05 if i == 0 else 0 for i in range(len(df_status_metrics))]

# 1. Prepara√ß√£o dos Labels para a Legenda (Nome do Status + Porcentagem)
# Iteramos sobre o dataframe para criar textos como "Closed - 85.2%"
total = df_status_metrics['total_cases'].sum()
legend_labels = [f'{row.status} - {row.total_cases/total*100:.1f}%' 
                 for _, row in df_status_metrics.iterrows()]

# 2. Plotagem "Limpa" (Sem textos na pizza)
patches, texts = plt.pie(
    df_status_metrics['total_cases'], 
    labels=None,      # Remove labels das fatias
    autopct=None,     # Remove porcentagem das fatias
    colors=colors,
    explode=explode,
    startangle=90
)

# 3. Legenda Lateral Enriquecida
plt.legend(
    patches,
    legend_labels,    # Aqui entram os textos com porcentagem
    title="Status - Distribui√ß√£o",
    loc="center left",
    bbox_to_anchor=(1, 0, 0.5, 1) # Posi√ß√£o lateral segura
)

plt.title('Distribui√ß√£o de Cases por Status', 
          fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.savefig('../output/figures/03_distribuicao_status.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo em: ../output/figures/03_distribuicao_status.png")

plt.show()

# %% [markdown]
# Visualiza√ß√£o 4: Tend√™ncia Temporal

# %%
# C√©lula 15: Gr√°fico de Linha - Tend√™ncia Temporal

# Garante ordena√ß√£o cronol√≥gica (essencial para gr√°ficos de linha)
df_temporal = df_temporal.sort_values('month')

fig, ax1 = plt.subplots(figsize=(16, 8))

# --- Eixo Principal (Esquerda): Volume de Casos ---
color1 = 'tab:blue'
ax1.set_xlabel('M√™s', fontsize=13)
ax1.set_ylabel('N√∫mero de Cases', color='#2c3e50', fontsize=13)

# Plot cases criados
ax1.plot(df_temporal['month'], df_temporal['cases_created'], 
         color='tab:blue', marker='o', linewidth=2, label='Cases Criados')

# Plot cases fechados
ax1.plot(df_temporal['month'], df_temporal['cases_closed'], 
         color='tab:green', marker='s', linewidth=2, label='Cases Fechados')

ax1.tick_params(axis='y', labelcolor='#2c3e50')
ax1.grid(True, alpha=0.3)
ax1.legend(loc='upper left')

# --- Eixo Secund√°rio (Direita): Efici√™ncia ---
ax2 = ax1.twinx()
color2 = 'tab:red'
ax2.set_ylabel('Tempo M√©dio de Resolu√ß√£o (dias)', color=color2, fontsize=13)

ax2.plot(df_temporal['month'], df_temporal['avg_resolution_days'], 
         color=color2, marker='^', linewidth=2, linestyle='--', label='Tempo M√©dio')

ax2.tick_params(axis='y', labelcolor=color2)
ax2.legend(loc='upper right') # Posi√ß√£o oposta para n√£o sobrepor

# T√≠tulos e Ajustes
plt.title('Evolu√ß√£o Temporal: Volume de Chamados vs Efici√™ncia', 
          fontsize=16, fontweight='bold', pad=20)
plt.xticks(rotation=45, ha='right')

fig.tight_layout()
plt.savefig('../output/figures/04_tendencia_temporal.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo em: ../output/figures/04_tendencia_temporal.png")

plt.show()

# %% [markdown]
# Visualiza√ß√£o 5: Matriz de Correla√ß√£o 

# %%
# C√©lula 16: Heatmap - Prioridade vs Status
# 1. Carregar dados
priority_status = pd.read_sql("""
    SELECT 
        case_priority as priority,
        case_status as status,
        COUNT(*) as count
    FROM cases
    GROUP BY case_priority, case_status
""", conn)

# 2. Pivotagem
pivot_table = priority_status.pivot(index='priority', columns='status', values='count').fillna(0)

# 3. Ordena√ß√£o L√≥gica (Do mais cr√≠tico para o menos cr√≠tico)
# Usamos a lista exata que voc√™ encontrou no banco
custom_order = ['Urgent', 'High', 'Normal', 'not_priority']

# Filtramos apenas o que realmente existe na tabela pivotada para evitar erros
existing_order = [p for p in custom_order if p in pivot_table.index]
pivot_table = pivot_table.reindex(existing_order)

# 4. Plotagem
plt.figure(figsize=(10, 6))
sns.heatmap(
    pivot_table, 
    annot=True, 
    fmt='g', 
    cmap='YlOrRd', # Vermelho para o que √© Urgente
    linewidths=0.5,
    cbar_kws={'label': 'Volume de Casos'}
)

plt.title('Matriz de Calor: Volume de Casos por Prioridade', fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Status Atual', fontsize=13)
plt.ylabel('Prioridade', fontsize=13)

plt.tight_layout()
plt.savefig('../output/figures/05_matriz_prioridade_status.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo em: ../output/figures/05_matriz_prioridade_status.png")

plt.show()

# %% [markdown]
# ## üí° Insights de Neg√≥cio
# 
# ### üéØ Insight 1: Risco de Concentra√ß√£o ("The Whale Client")
# 
# **Problema Identificado:**
# - **Cliente Outlier:** O cliente `Customer_900e52a5` (IT) representa **16.5%** de todos os casos.
# - **Volume:** 1.650 tickets (7x maior que o 2¬∫ colocado).
# - **Risco:** Backlog atual de 93 casos ativos, indicando potencial insatisfa√ß√£o/churn.
# 
# **Recomenda√ß√£o Estrat√©gica:**
# - ‚úÖ Implementar atendimento **White Glove** com Technical Account Manager (TAM) dedicado.
# - ‚úÖ Investigar hist√≥rico de tickets para criar automa√ß√£o/self-service espec√≠fico.
# - ‚úÖ **Meta:** Reduzir volume de tickets deste cliente em 20% em 3 meses.
# 
# ---
# 
# ### üéØ Insight 2: Inefici√™ncia Operacional (Duplicatas e Prioriza√ß√£o)
# 
# **Problema Identificado:**
# - **20.2% de Desperd√≠cio:** 2.015 casos s√£o duplicatas, consumindo tempo precioso de triagem.
# - **Prioriza√ß√£o Quebrada:** Apenas 2 casos "High" em todo hist√≥rico. A triagem √© bin√°ria: "Normal" ou "Urgent".
# - **Gargalo:** Casos novos ("New") t√™m idade m√©dia de 159 dias no backlog.
# 
# **Recomenda√ß√£o Estrat√©gica:**
# - ‚úÖ Implementar valida√ß√£o de duplicidade no Front-End (UX).
# - ‚úÖ Eliminar categoria "High" OU redefinir crit√©rios claros de SLA.
# - ‚úÖ **Meta:** Reduzir duplicatas para <5% e limpar o backlog antigo.
# 
# ---
# 
# ### üéØ Insight 3: Dados √ìrf√£os & Hegemonia Farmac√™utica
# 
# **Problema Identificado:**
# - **Blind Spot:** **1.593 casos** (15.9%) sem v√≠nculo com Account (orphan data).
# - **Impacto:** Impossibilita an√°lise de receita e ROI do suporte ("voo √†s cegas").
# - **Setor Cr√≠tico:** Pharmaceuticals representa 7 das top 15 contas por volume.
# 
# **Recomenda√ß√£o Estrat√©gica:**
# - ‚úÖ **Curto Prazo:** For√ßa-tarefa (ETL) para recuperar linkagem de casos √≥rf√£os.
# - ‚úÖ **M√©dio Prazo:** Criar Squad Especializada em Life Sciences/Pharma.
# - ‚úÖ **Meta:** Taxa de dados √≥rf√£os < 1% e aumentar CSAT do setor Pharma.


